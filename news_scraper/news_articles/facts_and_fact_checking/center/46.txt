Last week, Twitter tried something new. When President Trump tweeted that “There is NO WAY (ZERO!) that Mail-In Ballots will be anything less than substantially fraudulent,” Twitter appended this message to Trump’s tweet: “Get the facts about mail-in ballots” — which in turn, linked to a page with the headline: “Trump makes unsubstantiated claim that mail-in ballots will lead to voter fraud.”

Given the dangers misinformation poses to both democracy and public health, many believe social media platforms have a responsibility to monitor and correct misinformation before it spreads. But can corrections like this even work? And what role should social media platforms play in combating misinformation?

Well, it turns out there is evidence that fact checks do work. Numerous studies have demonstrated that when confronted with a correction, a significant share of people do, in fact, update their beliefs.

Political scientists Ethan Porter and Thomas J. Wood conducted an exhaustive battery of surveys on fact-checking, across more than 10,000 participants and 13 studies that covered a range of political, economic and scientific topics. They found that 60 percent of respondents gave accurate answers when presented with a correction, while just 32 percent of respondents who were not given a correction expressed accurate beliefs. That’s pretty solid proof that fact-checking can work.

But Porter and Wood have found, alongside many other fact-checking researchers, some methods of fact-checking are more effective than others. Broadly speaking, the most effective fact checks have this in common:

So despite a few studies suggesting that fact checks may make misinformation more prevalent (most prominently a widely-cited paper from political scientists Brendan Nyhan and Jason Reifler in 2010, which popularized the concept of the “backfire effect”), the overwhelming majority of studies have found that fact checks do work — or at the very least, do no harm. Still, some pieces of misinformation are harder to fight than others. And this episode involving Trump has several qualities that may make Twitter’s “get the facts” approach not exactly effective.

First, there’s the source: Donald Trump. Trust him or doubt him, chances are you have an opinion of the president. And if you already trust him, who are you going to trust more in this particular disagreement? Trump? Or CNN and the Washington Post (the two sources Twitter listed in its fact check)?

But given Trump’s notoriety, his misstatements may just be harder to combat. In one of Porter and Wood’s experiments, they took an op-ed by Trump and issued a correction on two versions of the piece: one (correctly) attributed to Trump and one attributed to Senate Majority Leader Mitch McConnell. The authors found that the fact-check of McConnell moved significantly more respondents toward the accurate position than did the fact check of Trump.

Next, there’s the fact that Twitter referenced articles from CNN and the Washington Post to correct the record. Research shows that an unlikely, surprising source for debunking misinformation, like a fellow Republican criticizing Trump, is just much more effective at making a correction stick than a more predictable and unsurprising source (like CNN or the Washington Post, both of which Trump has also cast as his enemies).

A Trump-supporting reader might take a closer look if told that Republican state officials in Idaho and Washington had complete confidence in the security of voting by mail, or that an exhaustive 17-month law enforcement inquiry into voter fraud in Florida, a state governed by fellow Republican Ron DeSantis, found no evidence of wrongdoing. This combination of surprise and credibility, in theory, would activate a closer look — the kind of attention required for mental updating.

And although Republicans en masse did not criticize Trump’s tweet that equated voting by mail with voter fraud, one recent example of a surprising debunk (and therefore, perhaps a maybe more effective fact check) is the Wall Street Journal’s editorial board’s take down of Trump’s allegation that cable news host Joe Scarborough was responsible for the death of a female staffer while he was a Republican congressman in Florida. The WSJ editorial board wrote that Trump’s suggestion “that the talk-show host is implicated in the woman’s death isn’t political hardball. It’s a smear.”

But fact-checking Trump is also further complicated by the fact that he is just really good at making memorable — if misleading or completely baseless — allegations. Remember Trump’s bizarre assertion that the hacker who released the DNC’s emails was not someone in Russia but instead “somebody sitting on their bed that weighs 400 pounds?” You probably do. It was a memorable, specific image, and catchy enough that “400poundhacker” briefly trended on Twitter. And as a memory expert will tell you, the more specific and outrageous the image, the more likely you are to remember it. This latest tweet was no exception. And this makes refuting Trump’s claim by simply dismissing it as “not true” especially ineffective. Political scientist Emily Thorson calls this phenomenon a “belief echo,” or the phenomenon that even when an idea is rejected as false, it can still continue to shape attitudes.

Think about someone like President Nixon saying “I’m not a crook” in response to the allegations that he oversaw a break-in at the Watergate Hotel to wiretap his political opponents. By refuting the allegation, he’s also repeating it, and therefore, making it more memorable. And the more evocative and colorful the original claim, the stronger the echo, Thorson finds, if the rejection also repeats the claim. “Unfortunately, this means that the times when we are most tempted to repeat misinformation — a horrifyingly inaccurate graph, an offensive comment in a debate — are also the times when it is most likely to create belief echoes,” Thorson wrote.

Rather than simply saying there is no evidence to support Trump’s claim that voting by mail will lead to widespread voter fraud, an effective fact check might offer an alternate explanation for why voting by mail doesn’t cause voter fraud. For instance, a good fact check could explain that many governors support voting-by-mail to protect vulnerable family members from getting sick from the coronavirus, not because they think it will benefit their party politically. Or it could detail all the specific measures governors are taking to ensure a secure process, like signature matching and ballot tracing.

But this brings us to perhaps the trickiest obstacles regarding effective corrections in this situation: partisanship and worldview. Research shows that people can easily incorporate new information — even if it’s inaccurate — as long as it fits in an existing worldview. Take Trump’s misstatement on voting by mail causing voter fraud. Even though there isn’t evidence to support this, it already fits within a preexisting narrative that many Republicans believe — that voter fraud is widespread and Democrats help perpetuate it. This is what makes the problem of combating misinformation so challenging.

When premises are familiar (e.g., Democrats perpetuate voter fraud), it’s easier to incorporate new information uncritically, especially when partisanship is involved. Partisans are typically much more receptive to any facts that make their side look good and any facts that make the other side look bad. Likewise, they’re likely to reject facts that make their side look bad and make the other side look good.

Practically, this has meant that as Democrats and Republicans have cocooned themselves in separate information streams, they’ve increasingly incorporated not only different worldviews, but also different sets of facts to support those worldviews. The more partisanship itself becomes an identity, the more intense this motivated reasoning has become.

But there is one thing that might make this particular correction effective: It was issued simultaneously with the misstatement. And research has shown that the most effective corrections are immediate responses. A team of researchers led by Nyhan recently found that “disputed” tags, like the one Twitter issued, successfully reduce belief in false stories on social media.

There’s a very real question, though, of how much these tech platforms should be controlling what we do — and don’t — see. Facebook, for instance, has taken a different approach than Twitter so far. Facebook founder and CEO Mark Zuckerberg criticized Twitter’s new policy, saying that, “I just believe strongly that Facebook shouldn’t be the arbiter of truth of everything that people say online.” Twitter and Facebook are also two of the very few places that both Democrats and Republicans turn to for news, even if their feeds rarely overlap.

Finally, even an effective fact check might not make the difference that policymakers are hoping for in political attitudes. While it’s possible for fact checks to shift beliefs, attitudes are much harder to change and much more resilient to fact checks.

In other words, even if some Twitter users now know that voting by mail doesn’t cause voter fraud, it’s unlikely that their attitudes about Trump will change, let alone their attitudes about voting by mail (they might find other reasons to oppose it, or still be concerned about the possibility of fraud, even if they don’t think it is widespread). After all, in our two-party system, it is still a tremendous leap for a Trump supporter to defect to voting for a Democrat. Fact-checking can help with updating and correcting prior knowledge, but breaking the hyper-partisanship that nurtures misinformation in the first place will require a whole lot more work.

But the more aggressively Twitter combats misinformation coming from Trump, the more it risks both the ire of the Trump administration and a potential loss of angered Republican users. A more comprehensive corrections department that fact checks all public figures (not just Trump) might allay some criticisms from the right that Twitter is biased against conservatives. But it would also cost money to employ more fact-checkers, and it might still disproportionately correct conservative voices if they do share more misleading information than liberals. If so, the information echo-chambers may fracture further, with liberals and conservatives seeking out their own platforms even more. That could make fact-checking even harder.

Social media companies will have to balance competing demands in deciding exactly how — and how much — they want to correct misinformation. The good news is that fact-checking does work. But the bad news is that it’s going to take a lot of concerted fact-checking efforts to make any difference — and even that might not be enough.

Confidence Interval: If Trump Loses In 2020, He’ll Be The Nominee Again In 2024