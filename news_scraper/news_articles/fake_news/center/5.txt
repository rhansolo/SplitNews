While public health and government officials scramble to contain the spread of COVID-19 around the United States, some lawmakers are seeking to address another scourge: online disinformation about the virus that could pose health risks and sow division among Americans.

False information about the virus has spread quickly across the internet in recent months, taking the form of misinformation — inaccurate information spread unwittingly by social media users, such as those about supposed vaccines for the virus — and more malicious disinformation, which can be spread by “bots” deployed by Russia, China or other adversaries.

Technology companies Google, Facebook and Twitter have each taken steps to curb the spread of misinformation and disinformation on their platforms, but it’s nearly impossible to stop it completely. Recently, lawmakers on Capitol Hill who have already called on Silicon Valley to do more are beginning to shape legislative action, although it’s unclear what could become law.

“The spread of false and potentially dangerous claims during a lethal pandemic clearly poses a threat to our national security,” said Rep. Lauren Underwood, D-Ill., at a virtual forum on disinformation hosted by the House Homeland Security Committee last month. “When it comes to vital public health information, the stakes are life and death.”

Underwood said she planned to introduce legislation in the coming weeks to “address the impact and the threat of disinformation to public health and safety.”